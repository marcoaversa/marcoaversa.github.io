---
---


@article{ivanova2024visart,
  abbr={ECCV},
  title={State-of-the-Art Fails in the Art of Damage Detection},
  author={Daniela Ivanova and Marco Aversa and Paul Henderson and John Williamson},
  journal={ECCV 2024 Vision for Art Workshop VISART},
  year={2024},
  abstract={Accurately detecting and classifying damage in analogue media such as paintings, photographs, textiles, mosaics, 
  and frescoes is essential for cultural heritage preservation. While machine learning models excel in correcting global degradation 
  if the damage operator is known a priori, we show that they fail to predict where the damage is even after supervised training; 
  thus, reliable damage detection remains a challenge. We introduce DamBench, a dataset for damage detection in diverse analogue media, 
  with over 11,000 annotations covering 15 damage types across various subjects and media. We evaluate CNN, Transformer, and 
  text-guided diffusion segmentation models, revealing their limitations in generalising across media types.},
  website={https://visarts.eu},
}

@article{nobis2023generative,
  abbr={ICML},
  title={Generative Fractional Diffusion Models},
  author={Gabriel Nobis and Maximilian Springenberg and Marco Aversa and Michael Detzel and Stefano Ermon and Shinichi Nakajima and Roderick Murray-Smith and Sebastian Lapuschkin and Christoph Knochenhauer and Luis Oala and Wojciech Samek},
  journal={ICML 2024 Workshop on Structured Probabilistic Inference & Generative Modeling},
  year={2024},
  abstract={We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM)
   to an approximation of fractional Brownian motion (FBM). We derive a continuous reparameterization trick and the reverse time 
   model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional 
   diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation. The Hurst 
   index $H\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path. To the best of our knowledge, 
   this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.},
}


@article{nobis2023generative,
  abbr={NeurIPS},
  title={Generative Fractional Diffusion Models},
  author={Gabriel Nobis and Maximilian Springenberg and Marco Aversa and Michael Detzel and Stefano Ermon and Shinichi Nakajima and Roderick Murray-Smith and Sebastian Lapuschkin and Christoph Knochenhauer and Luis Oala and Wojciech Samek},
  journal={NeurIPS 2023 Workshop on Diffusion Models},
  year={2023},
  abstract={We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM)
   to an approximation of fractional Brownian motion (FBM). We derive a continuous reparameterization trick and the reverse time 
   model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional 
   diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation. The Hurst 
   index $H\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path. To the best of our knowledge, 
   this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.},
  website={https://neurips.cc/virtual/2023/74891},
}

@article{oala2023datadiff,
  abbr={ICML},
  title={Data Models for Dataset Drift Controls in Machine Learning With Optical Images},
  author={Oala, Luis and Aversa, Marco and Nobis, Gabriel and Willis, Kurt and Neuenschwander, Yoan and Buck, Mich{\`e}le and Matek, Christian and Extermann, Jerome and Pomarico, Enrico and Samek, Wojciech and others},
  abstract={Camera images are ubiquitous in machine learning research. 
  They also play a central role in the delivery of important public services spanning medicine or environmental surveying. 
  However, the application of machine learning models in these domains has been limited because of robustness concerns. 
  A primary failure mode are performance drops due to differences between the training and deployment data. 
  While there are methods to prospectively validate the robustness of machine learning models to such dataset drifts, 
  existing approaches do not account for explicit models of machine learning's primary object of interest: 
  the data. This limits our ability to study and understand the relationship between data generation and 
  downstream machine learning model performance in a physically accurate manner. 
  In this study, we demonstrate how to overcome this limitation by pairing traditional machine learning 
  with physical optics to obtain explicit and differentiable data models. We demonstrate how such data models can 
  be constructed for image data and used to control downstream machine learning model performance related to dataset drift. 
  The findings are distilled into three applications. First, drift synthesis enables the controlled generation of physically 
  faithful drift test cases to power model selection and targeted generalization. Second, the gradient connection between 
  machine learning task model and data model allows advanced, precise tolerancing of task model sensitivity to changes 
  in the data generation. These drift forensics can be used to precisely specify the acceptable data environments in which 
  a task model may be run. Third, drift optimization opens up the possibility to create drifts that can help the task model 
  learn better faster, effectively optimizing the data generating process itself to support the downstream machine vision task. 
  This is an interesting upgrade to existing imaging pipelines which traditionally have been optimized to be consumed by human 
  users but not machine learning models. Alongside the data model code we release two datasets to the public that we collected 
  as part of this work. In total, the two datasets, Raw-Microscopy and Raw-Drone, comprise 1,488 scientifically calibrated reference 
  raw sensor measurements, 8,928 raw intensity variations as well as 17,856 images processed through twelve data models with different 
  configurations. A guide to access the open code and datasets is available at https://github.com/aiaudit-org/raw2logit.},
  journal={International Conference on Machine Learning, Differentiable Almost Everything Workshop},
  year={2023},
}

@article{oala2023dataspurious,
  abbr={ICML},
  title={Data Models for Dataset Drift Controls in Machine Learning With Optical Images},
  author={Oala, Luis and Aversa, Marco and Nobis, Gabriel and Willis, Kurt and Neuenschwander, Yoan and Buck, Mich{\`e}le and Matek, Christian and Extermann, Jerome and Pomarico, Enrico and Samek, Wojciech and others},
  abstract={Camera images are ubiquitous in machine learning research. 
  They also play a central role in the delivery of important public services spanning medicine or environmental surveying. 
  However, the application of machine learning models in these domains has been limited because of robustness concerns. 
  A primary failure mode are performance drops due to differences between the training and deployment data. 
  While there are methods to prospectively validate the robustness of machine learning models to such dataset drifts, 
  existing approaches do not account for explicit models of machine learning's primary object of interest: 
  the data. This limits our ability to study and understand the relationship between data generation and 
  downstream machine learning model performance in a physically accurate manner. 
  In this study, we demonstrate how to overcome this limitation by pairing traditional machine learning 
  with physical optics to obtain explicit and differentiable data models. We demonstrate how such data models can 
  be constructed for image data and used to control downstream machine learning model performance related to dataset drift. 
  The findings are distilled into three applications. First, drift synthesis enables the controlled generation of physically 
  faithful drift test cases to power model selection and targeted generalization. Second, the gradient connection between 
  machine learning task model and data model allows advanced, precise tolerancing of task model sensitivity to changes 
  in the data generation. These drift forensics can be used to precisely specify the acceptable data environments in which 
  a task model may be run. Third, drift optimization opens up the possibility to create drifts that can help the task model 
  learn better faster, effectively optimizing the data generating process itself to support the downstream machine vision task. 
  This is an interesting upgrade to existing imaging pipelines which traditionally have been optimized to be consumed by human 
  users but not machine learning models. Alongside the data model code we release two datasets to the public that we collected 
  as part of this work. In total, the two datasets, Raw-Microscopy and Raw-Drone, comprise 1,488 scientifically calibrated reference 
  raw sensor measurements, 8,928 raw intensity variations as well as 17,856 images processed through twelve data models with different 
  configurations. A guide to access the open code and datasets is available at https://github.com/aiaudit-org/raw2logit.},
  journal={International Conference on Machine Learning, Spurious Correlations, Invariance, and Stability Workshop},
  year={2023}
}

@article{aversaphysical,
  abbr={NeurIPS},
  award={Contributed Talk},
  title={Physical Data Models in Machine Learning Imaging Pipelines},
  journal={Advances in Neural Information Processing Systems, Machine Learning and the Physical Science Workshop},
  author={Aversa, Marco and Oala, Luis and Clausen, Christoph and Murray-Smith, Roderick and Sanguinetti, Bruno},
  pdf={https://ml4physicalsciences.github.io/2022/files/NeurIPS_ML4PS_2022_136.pdf},
  website={https://neurips.cc/virtual/2022/56248},
  abstract={Light propagates from the object through the optics up to the sensor to create an
  image. Once the raw data is collected, it is processed through a complex image
  signal processing (ISP) pipeline to produce an image compatible with human
  perception. However, this processing is rarely considered in machine learning
  modelling because available benchmark data sets are generally not in raw format.
  This study shows how to embed the forward acquisition process into the machine
  learning model. We consider the optical system and the ISP separately. Following
  the acquisition process, we start from a drone and airship image dataset to emulate
  realistic satellite raw images with on-demand parameters. The end-to-end process
  is built to resemble the optics and sensor of the satellite setup. These parameters
  are satellite mirror size, focal length, pixel size and pattern, exposure time and
  atmospheric haze. After raw data collection, the ISP plays a crucial role in neural
  network robustness. We jointly optimize a parameterized differentiable image
  processing pipeline with a neural network model. This can lead to speed up and
  stabilization of classifier training at a margin of up to 20\% in validation accuracy.},
  year={2022}
}